# Daily SLA Reporting Automation System

## Structure
```
DailySLAReporting/
â”œâ”€â”€ daily_reporter.py          # Main automation script
â”œâ”€â”€ 2026-01-22/               # Today's date folder (auto-created)
â”‚   â””â”€â”€ Report_1_Comms_Reporting/
â”‚       â”œâ”€â”€ raw_data/         # Place your raw files here
â”‚       â””â”€â”€ output/           # Final reports will be saved here
â””â”€â”€ README.md
```

## How It Works

1. **Automatic Date Detection**: The system automatically uses today's date (2026-01-22)
2. **Raw Data Location**: Place raw data files in `[DATE]/Report_1_Comms_Reporting/raw_data/`
3. **One-Time Daily Run**: Execute `python daily_reporter.py` once per day
4. **Output Generation**: Final reports will be saved in `[DATE]/Report_1_Comms_Reporting/output/`

## Quick Start

1. Place your raw data files in the `raw_data` folder
2. Run the script:
   ```bash
   python daily_reporter.py
   ```
3. Check output files in the `output` folder

## Next Steps

We'll configure this for your specific data format and processing logic.
>>>>>>> f15a250 (Initial commit: Daily SLA Reporting System with file validation and summary generation)
# Daily SLA Reporting Automation System

## Overview

Automated system for processing daily SLA (Service Level Agreement) meter communication data. Merges data from multiple sources, validates files, calculates communication status, and generates comprehensive reports including subdivision-level breakdowns.

**Perfect for:** Utility companies, smart meter operations teams, field service management

## Key Features

âœ… **Automatic Folder Creation** - Creates daily folder structure at 10 AM (or on-demand)
âœ… **File Validation** - Checks file names and column headers before processing
âœ… **Multi-Source Data Merging** - Combines Warehouse, Node ID, Routing, and other data sources
âœ… **Communication Status** - Calculates Communicating/Never Comm/Non Comm status
âœ… **Subdivision Analysis** - Breaks down communication status by subdivision
âœ… **Multiple Output Formats** - Generates CSV reports and JSON summaries
âœ… **Detailed Logging** - Terminal output shows progress and validation results
âœ… **Cross-Platform** - Works on Windows, Mac, and Linux

## System Architecture

```
SharePoint/OneDrive (Cloud Storage)
    â†“
    â†“ Syncs to local machine
    â†“
Local Processing (Python Script)
    â†“
    â”‚â”€â”€ Validates files
    â”‚â”€â”€ Merges data sources  
    â”‚â”€â”€ Calculates comm status
    â”‚â”€â”€ Generates reports
    â†“
Output Files (Back to SharePoint)
    â”‚â”€â”€ Final_SLA_Report.csv (Main report)
    â”‚â”€â”€ Communication_Status_Summary.csv (Management summary)
    â”‚â”€â”€ Master/Intermediate reports (Detailed data)
    â””â”€â”€ JSON summary (Technical metadata)
```

## Quick Start

### For Windows Users (Recommended Setup)

1. **Install Python 3.7+** from [python.org](https://python.org)
   - âš ï¸ Check "Add Python to PATH" during installation

2. **Clone this repository:**
   ```cmd
   git clone https://github.com/aiboybatra-ops/SLA_reports_Kimbal.git
   cd SLA_reports_Kimbal
   ```
   
   Or download ZIP from GitHub and extract to Desktop

3. **Configure SharePoint path:**
   - Edit `daily_reporter.py` (line ~920)
   - Update `sharepoint_path` with your OneDrive sync location:
     ```python
     sharepoint_path = Path('C:/Users/YourUsername/OneDrive - Company/Communication site - Daily_SLA_Reporting')
     ```

4. **Run the script:**
   ```cmd
   python daily_reporter.py
   ```

5. **Upload your data files** to the created folders in SharePoint

6. **Run again to process** the data and generate reports

ðŸ“š **For detailed step-by-step instructions, see [user_instructions.txt](user_instructions.txt)**

## Folder Structure

```
SharePoint/OneDrive Root/
â””â”€â”€ Communication site - Daily_SLA_Reporting/
    â””â”€â”€ 2026-01-23/                          (Auto-created daily)
        â””â”€â”€ Report_1_Comms_Reporting/
            â”œâ”€â”€ DG1/
            â”‚   â”œâ”€â”€ raw_data/                  (Upload your data here)
            â”‚   â”‚   â”œâ”€â”€ Warehouse.csv
            â”‚   â”‚   â”œâ”€â”€ New_Service_connection.csv
            â”‚   â”‚   â”œâ”€â”€ Merged_CI-MI.csv
            â”‚   â”‚   â”œâ”€â”€ Meter_Installation.csv
            â”‚   â”‚   â”œâ”€â”€ Node ID.xlsx
            â”‚   â”‚   â”œâ”€â”€ Routings Part-1.xlsx
            â”‚   â”‚   â””â”€â”€ Routings Part-2.xlsx
            â”‚   â””â”€â”€ output/                    (Generated reports appear here)
            â”‚       â”œâ”€â”€ Final_SLA_Report_2026-01-23.csv
            â”‚       â”œâ”€â”€ Communication_Status_Summary_DG1_2026-01-23.csv
            â”‚       â”œâ”€â”€ Master_SLA_Report_2026-01-23.csv
            â”‚       â”œâ”€â”€ Intermediate_SLA_Report_2026-01-23.csv
            â”‚       â””â”€â”€ SLA_Summary_DG1_2026-01-23.json
            â”œâ”€â”€ DG2/
            â”‚   â”œâ”€â”€ raw_data/
            â”‚   â””â”€â”€ output/
            â””â”€â”€ DG3/
                â”œâ”€â”€ raw_data/
                â””â”€â”€ output/
```

## Required Input Files

| File Name | Format | Purpose | Key Columns |
|-----------|--------|---------|-------------|
| Warehouse.csv | CSV | Base meter inventory | Meter Serial No, Consumer Name, Address, Division |
| New_Service_connection.csv | CSV | New installations | New Meter QR Code, Consumer name, Subdivision |
| Merged_CI-MI.csv | CSV | Inspection data | New Meter QR Code, Feeder Name, Coordinates |
| Meter_Installation.csv | CSV | Installation records | New Meter Number Scan, Installation date |
| Node ID.xlsx | Excel | Node mapping | Meter Number, NodeId |
| Routings Part-1.xlsx | Excel | Communication routing | Node ID, Gateway ID, Communicated At |
| Routings Part-2.xlsx | Excel | Additional routing data | Node ID, Gateway ID, Communicated At |

## Output Files

### 1. Final_SLA_Report_[DATE].csv
â­ **Primary Report** - Complete meter data with communication status

**Columns include:**
- Meter Serial No, Node ID, Manufacturer
- Consumer information (Name, Address, Mobile)
- Location (Division, Subdivision, Circle, Feeder)
- Coordinates (Latitude, Longitude)
- Routing (Gateway ID, Hop Count, Sink ID)
- **Comm Status** (Communicating / Never Comm / Non Comm)
- **Remarks** (Blank for manual notes)

### 2. Communication_Status_Summary_[DATE].csv
â­ **Management Dashboard** - High-level status overview

**Format:**
| Category | Subdivision | Communicating | Never Comm | Non Comm | Total |
|----------|-------------|---------------|------------|----------|-------|
| Overall | All | 1250 | 340 | 210 | 1800 |
| By Subdivision | North Division | 450 | 120 | 80 | 650 |
| By Subdivision | South Division | 380 | 95 | 70 | 545 |

### 3. Master_SLA_Report_[DATE].csv
Complete merged dataset with all columns from all sources (50-100+ columns)

### 4. Intermediate_SLA_Report_[DATE].csv
Cleaned dataset with essential columns only (~20 columns)

### 5. SLA_Summary_DG[X]_[DATE].json
Technical metadata including missing data analysis and mapping statistics

## Communication Status Definitions

| Status | Definition | Meaning |
|--------|------------|----------|
| **Communicating** | Communicated today | âœ… Meter is active and working |
| **Non Comm** | Communicated before, but not today | âš ï¸ Meter stopped communicating - needs attention |
| **Never Comm** | Never communicated | âš ï¸ New meter or faulty installation |

## Data Processing Workflow

1. **Validation Phase:**
   - Check all 7 required files are present
   - Verify file names match exactly
   - Validate column headers in each file

2. **Merging Phase:**
   - Start with Warehouse.csv as base (master list of meters)
   - Merge New_Service_connection.csv on meter QR code
   - Merge Merged_CI-MI.csv for inspection data
   - Merge Meter_Installation.csv for installation details
   - Merge Node ID.xlsx to map meters to network nodes
   - Merge Routing files to get communication data

3. **Processing Phase:**
   - Coalesce data from multiple sources (fill blanks)
   - Select essential columns for intermediate report
   - Calculate communication status based on "Communicated At" field
   - Generate subdivision-level summaries

4. **Output Phase:**
   - Save Master report (all data)
   - Save Intermediate report (selected columns)
   - Save Final report (with comm status)
   - Generate CSV summary (overall + subdivision)
   - Create JSON metadata

## Validation & Error Handling

### Automatic Validations:

âœ… **File Name Validation**
- Checks all 7 files are present
- Verifies exact name matching (case-sensitive)
- Identifies missing or incorrectly named files

âœ… **Column Validation**
- Checks each file has required column headers
- Reports missing columns
- Warns about extra columns

âœ… **Data Completeness**
- Tracks which records successfully merged
- Reports unmapped data from each source
- Counts missing Node IDs and routing info

### Error Messages:

```
âŒ FILE VALIDATION ISSUES:
  Missing files: ['Node ID.xlsx']
  Unexpected files: ['node_id.xlsx']

â†’ Fix: Rename 'node_id.xlsx' to 'Node ID.xlsx'
```

```
âŒ Column validation failed
  Warehouse.csv:
    Missing columns: ['Meter Serial No']
    
â†’ Fix: Check column headers in row 1 of CSV file
```

## System Requirements

### Minimum Requirements:
- **OS:** Windows 10+, macOS 10.14+, or Linux
- **Python:** 3.7 or higher
- **RAM:** 4 GB (8 GB recommended for large datasets)
- **Storage:** 500 MB free space
- **Network:** Internet connection for OneDrive sync

### Python Dependencies:
```
pandas>=1.3.0
openpyxl>=3.0.0
requests>=2.25.0
```

Install with:
```bash
pip install pandas openpyxl requests
```

## Performance

| Dataset Size | Records | Processing Time |
|--------------|---------|------------------|
| Small | < 5,000 | 30-60 seconds |
| Medium | 5,000-20,000 | 1-3 minutes |
| Large | 20,000-50,000 | 3-5 minutes |
| Very Large | > 50,000 | 5-10 minutes |

*Tested on Intel i5 processor with 8GB RAM*

## Scheduling (Optional)

### Option 1: Windows Task Scheduler
Schedule the script to run automatically at 10 AM daily

### Option 2: Cron (Mac/Linux)
Add to crontab:
```bash
0 10 * * * /usr/bin/python3 /path/to/daily_reporter.py >> /path/to/cron.log 2>&1
```

### Option 3: Manual Execution
Run on-demand whenever needed

## Troubleshooting

### Common Issues:

**"python is not recognized"**
- Python not installed or not in PATH
- Solution: Reinstall Python with "Add to PATH" checked

**"SharePoint base path does not exist"**
- OneDrive not syncing or incorrect path
- Solution: Verify OneDrive is running and path is correct

**"FILE VALIDATION ISSUES"**
- Missing or incorrectly named files
- Solution: Check file names match exactly (case-sensitive)

**"Column validation failed"**
- Incorrect column headers in CSV/Excel files
- Solution: Fix column names in row 1 of data files

**Script runs but no output**
- Files may be locked by Excel
- Solution: Close all Excel files and re-run

ðŸ“š **For detailed troubleshooting, see [user_instructions.txt](user_instructions.txt)**

## Best Practices

1. âœ… **Run daily** - Process overnight data fresh each morning
2. âœ… **Check sync** - Verify OneDrive is "Up to date" before running
3. âœ… **Review summaries** - Scan terminal output for anomalies
4. âœ… **Keep history** - Don't delete old reports (each day has its own folder)
5. âœ… **Backup data** - Occasionally copy raw_data folders to backup location
6. âœ… **Monitor quality** - Check data completeness and missing counts

## Security & Privacy

- ðŸ”’ Runs **100% locally** on your machine
- ðŸ”’ No data sent to external servers
- ðŸ”’ All processing happens offline
- ðŸ”’ Data stays within your SharePoint/OneDrive
- ðŸ”’ No API keys or credentials required

## Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## Support

For issues or questions:
- ðŸ› **Report bugs:** [GitHub Issues](https://github.com/aiboybatra-ops/SLA_reports_Kimbal/issues)
- ðŸ“š **Documentation:** See [user_instructions.txt](user_instructions.txt)
- ðŸ“§ **Contact:** [Your support email]

## License

MIT License - See LICENSE file for details

## Version History

### v2.0 (Current) - January 2026
- âœ¨ Added automatic folder structure creation
- âœ¨ Added CSV summary report with subdivision breakdown  
- âœ¨ Improved validation and error messages
- âœ¨ Added comprehensive Windows user documentation
- ðŸ› Fixed merge key matching issues
- ðŸ› Improved performance for large datasets

### v1.0 - Initial Release
- Basic data processing and merging
- JSON summary output
- File and column validation

## Acknowledgments

Developed for utility smart meter operations teams to streamline daily SLA reporting and communication status tracking.

---

**ðŸš€ Ready to get started? See [user_instructions.txt](user_instructions.txt) for complete setup guide!**
=======
# Daily SLA Reporting Automation System

## Structure
```
DailySLAReporting/
â”œâ”€â”€ daily_reporter.py          # Main automation script
â”œâ”€â”€ 2026-01-22/               # Today's date folder (auto-created)
â”‚   â””â”€â”€ Report_1_Comms_Reporting/
â”‚       â”œâ”€â”€ raw_data/         # Place your raw files here
â”‚       â””â”€â”€ output/           # Final reports will be saved here
â””â”€â”€ README.md
```

## How It Works

1. **Automatic Date Detection**: The system automatically uses today's date (2026-01-22)
2. **Raw Data Location**: Place raw data files in `[DATE]/Report_1_Comms_Reporting/raw_data/`
3. **One-Time Daily Run**: Execute `python daily_reporter.py` once per day
4. **Output Generation**: Final reports will be saved in `[DATE]/Report_1_Comms_Reporting/output/`

## Quick Start

1. Place your raw data files in the `raw_data` folder
2. Run the script:
   ```bash
   python daily_reporter.py
   ```
3. Check output files in the `output` folder

## Next Steps

We'll configure this for your specific data format and processing logic.
>>>>>>> f15a250 (Initial commit: Daily SLA Reporting System with file validation and summary generation)
